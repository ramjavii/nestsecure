# =============================================================================
# NESTSECURE - DÃ­a 6: IntegraciÃ³n API â†” Workers + Testing
# =============================================================================
# Fecha: 2026-02-02
# Objetivo: Integrar completamente la API de Scans con los Workers de Celery
# =============================================================================

## ğŸ“Š Resumen de ImplementaciÃ³n

| Componente | Estado | Tests | Notas |
|------------|--------|-------|-------|
| API â†’ Celery Integration | âœ… Completado | - | Despacho automÃ¡tico de tareas |
| Worker â†’ DB Updates | âœ… Completado | 25/25 | ActualizaciÃ³n de estado en tiempo real |
| CancelaciÃ³n Real | âœ… Completado | - | Revoke de tareas en Celery |
| Tests de Workers | âœ… Completado | 25/25 | Cobertura completa |
| Tests de Scans API | âœ… Actualizado | +1 | Mock de Celery |

**Tests DÃ­a 6:** 25 nuevos tests de workers
**Tests Acumulados:** 259 tests (234 anteriores + 25 nuevos)
**DuraciÃ³n:** ~4 horas

---

## âœ… Tareas Completadas

### 1. IntegraciÃ³n API â†’ Celery Workers

#### Flujo de CreaciÃ³n de Scan

```
Usuario â†’ POST /api/v1/scans â†’ ValidaciÃ³n â†’ Crear en DB
                                          â†“
                           execute_scan_task.delay()
                                          â†“
                              Celery Queue (scanning)
                                          â†“
                              Worker ejecuta Nmap
                                          â†“
                              Actualiza DB (status, progress)
                                          â†“
                              Crea vulnerabilidades/servicios
```

#### CÃ³digo de IntegraciÃ³n (`scans.py`)

```python
# Despachar tarea a Celery segÃºn el tipo de scan
try:
    from app.workers.nmap_worker import execute_scan_task
    
    task = execute_scan_task.delay(
        scan_id=scan.id,
        scan_type=scan_in.scan_type,
        targets=validated_targets,
        organization_id=organization_id,
        port_range=scan_in.port_range,
        engine_config=scan_in.engine_config or {},
    )
    
    # Guardar el ID de la tarea en el scan
    scan.celery_task_id = task.id
    scan.status = ScanStatus.QUEUED.value
    scan.add_log(f"Tarea Celery iniciada: {task.id}", "info")
    
except Exception as e:
    scan.status = ScanStatus.FAILED.value
    scan.error_message = f"Error al encolar tarea: {str(e)}"
```

---

### 2. Worker â†’ DB Updates

#### Tarea Principal: `execute_scan_task`

La tarea orquesta todo el flujo de escaneo:

```python
@shared_task(
    name="app.workers.nmap_worker.execute_scan_task",
    bind=True,
    max_retries=3,
    soft_time_limit=3300,
    time_limit=3600,
)
def execute_scan_task(
    self,
    scan_id: str,
    scan_type: str,
    targets: list[str],
    organization_id: str,
    port_range: str | None = None,
    engine_config: dict | None = None,
) -> dict:
    """
    Tarea principal que ejecuta un scan completo.
    
    1. Obtiene scan de DB y marca como RUNNING
    2. Ejecuta scan segÃºn tipo (discovery, port_scan, full)
    3. Actualiza progreso en DB
    4. Crea assets/services/vulnerabilidades
    5. Marca scan como COMPLETED o FAILED
    """
```

#### Estados del Scan

| Estado | DescripciÃ³n | Momento |
|--------|-------------|---------|
| `queued` | Tarea enviada a Celery | POST /scans exitoso |
| `running` | Worker procesando | Worker inicia |
| `completed` | Scan finalizado | Worker termina OK |
| `failed` | Error en ejecuciÃ³n | ExcepciÃ³n en worker |
| `cancelled` | Cancelado por usuario | PATCH /cancel |

#### ActualizaciÃ³n de Progreso

```python
# Dentro del worker
scan.update_progress(25)  # Iniciando
db.commit()

# DespuÃ©s de cada target
for i, target in enumerate(targets):
    progress = int((i + 1) / len(targets) * 100)
    scan.update_progress(progress)
    db.commit()

# Al finalizar
scan.complete()  # status=completed, progress=100
db.commit()
```

---

### 3. CancelaciÃ³n Real de Scans

#### Endpoint de CancelaciÃ³n

```python
@router.patch("/{scan_id}/cancel")
async def cancel_scan(...):
    # Cancelar tarea en Celery si existe
    if scan.celery_task_id:
        try:
            cancel_task(scan.celery_task_id)
            logger.info(f"Tarea Celery {scan.celery_task_id} cancelada")
        except Exception as e:
            logger.warning(f"Error cancelando tarea: {e}")
    
    scan.cancel()  # status=cancelled
    await db.commit()
```

#### FunciÃ³n de CancelaciÃ³n en Celery

```python
def cancel_task(task_id: str, terminate: bool = True) -> bool:
    """
    Cancela una tarea de Celery.
    
    Args:
        task_id: ID de la tarea a cancelar
        terminate: Si True, termina el proceso (SIGTERM)
    
    Returns:
        True si se enviÃ³ la seÃ±al de cancelaciÃ³n
    """
    celery_app.control.revoke(task_id, terminate=terminate)
    return True
```

---

### 4. Tests de Workers (25 tests)

#### Estructura de Tests

```
test_workers/
â””â”€â”€ test_nmap_worker.py (25 tests)
    â”œâ”€â”€ TestParseDiscoveryXml (5 tests)
    â”‚   â”œâ”€â”€ test_parse_discovery_finds_up_hosts
    â”‚   â”œâ”€â”€ test_parse_discovery_ignores_down_hosts
    â”‚   â”œâ”€â”€ test_parse_discovery_empty_xml
    â”‚   â”œâ”€â”€ test_parse_discovery_invalid_xml
    â”‚   â””â”€â”€ test_parse_discovery_handles_missing_hostname
    â”‚
    â”œâ”€â”€ TestParsePortScanXml (4 tests)
    â”‚   â”œâ”€â”€ test_parse_port_scan_extracts_host_info
    â”‚   â”œâ”€â”€ test_parse_port_scan_extracts_services
    â”‚   â”œâ”€â”€ test_parse_port_scan_empty_xml
    â”‚   â””â”€â”€ test_parse_port_scan_invalid_xml
    â”‚
    â”œâ”€â”€ TestRunNmap (4 tests)
    â”‚   â”œâ”€â”€ test_run_nmap_success
    â”‚   â”œâ”€â”€ test_run_nmap_timeout
    â”‚   â”œâ”€â”€ test_run_nmap_error
    â”‚   â””â”€â”€ test_run_nmap_host_down_not_error
    â”‚
    â”œâ”€â”€ TestDiscoveryScanTask (2 tests)
    â”‚   â”œâ”€â”€ test_discovery_scan_creates_assets
    â”‚   â””â”€â”€ test_discovery_scan_updates_existing_assets
    â”‚
    â”œâ”€â”€ TestPortScanTask (2 tests)
    â”‚   â”œâ”€â”€ test_port_scan_creates_services
    â”‚   â””â”€â”€ test_port_scan_asset_not_found
    â”‚
    â”œâ”€â”€ TestExecuteScanTask (3 tests)
    â”‚   â”œâ”€â”€ test_execute_scan_discovery_updates_db
    â”‚   â”œâ”€â”€ test_execute_scan_cancelled_scan_aborts
    â”‚   â””â”€â”€ test_execute_scan_not_found
    â”‚
    â”œâ”€â”€ TestErrorHandling (2 tests)
    â”‚   â”œâ”€â”€ test_nmap_timeout_handled
    â”‚   â””â”€â”€ test_parse_invalid_xml_no_crash
    â”‚
    â””â”€â”€ TestEdgeCases (3 tests)
        â”œâ”€â”€ test_parse_discovery_ipv6
        â”œâ”€â”€ test_parse_port_scan_no_version
        â””â”€â”€ test_parse_discovery_multiple_ips
```

#### Ejemplo de Test con Mock

```python
@patch("app.workers.nmap_worker.get_sync_db")
@patch("app.workers.nmap_worker.run_nmap")
def test_execute_scan_discovery_updates_db(self, mock_run_nmap, mock_get_db):
    """Debe actualizar el scan en DB durante discovery."""
    from app.workers.nmap_worker import execute_scan_task
    
    mock_run_nmap.return_value = SAMPLE_DISCOVERY_XML
    
    mock_scan = Mock()
    mock_scan.id = "scan-123"
    mock_scan.status = "queued"
    mock_scan.start = Mock()
    mock_scan.complete = Mock()
    
    mock_db = MagicMock()
    mock_db.execute.return_value.scalar_one_or_none.side_effect = [
        mock_scan,  # Initial scan lookup
        None, None,  # Asset lookups
    ]
    mock_get_db.return_value = mock_db
    
    result = execute_scan_task(
        scan_id="scan-123",
        scan_type="discovery",
        targets=["192.168.1.0/24"],
        organization_id="org-123",
    )
    
    assert result["success"] is True
    mock_scan.start.assert_called_once()
    mock_scan.complete.assert_called_once()
```

---

### 5. Correcciones Realizadas

#### 5.1 Test de CreaciÃ³n de Scan

El test original fallaba porque no mockeaba Celery:

```python
# ANTES (fallaba sin Celery corriendo)
async def test_create_scan_success(self, api_client, auth_headers_operator):
    response = await api_client.post("/api/v1/scans", ...)
    assert data["status"] == "pending"  # âŒ Era "failed"

# DESPUÃ‰S (con mock de Celery)
@patch('app.workers.nmap_worker.execute_scan_task')
async def test_create_scan_success(self, mock_task, api_client, auth_headers_operator):
    mock_async_result = Mock()
    mock_async_result.id = "test-task-id-123"
    mock_task.delay.return_value = mock_async_result
    
    response = await api_client.post("/api/v1/scans", ...)
    assert data["status"] == "queued"  # âœ… Correcto
    mock_task.delay.assert_called_once()
```

#### 5.2 Compatibilidad bcrypt

Se detectÃ³ incompatibilidad entre bcrypt 5.0 y passlib:

```bash
# Error
AttributeError: module 'bcrypt' has no attribute '__about__'

# SoluciÃ³n
pip install "bcrypt<5.0.0"
```

---

## ğŸ“ Archivos Modificados

| Archivo | Cambios | LÃ­neas |
|---------|---------|--------|
| `api/v1/scans.py` | IntegraciÃ³n Celery | +50 |
| `workers/nmap_worker.py` | execute_scan_task | +200 |
| `workers/celery_app.py` | cancel_task, get_task_status | +30 |
| `tests/test_workers/test_nmap_worker.py` | Tests completos | +580 |
| `tests/test_api/test_scans.py` | Mock de Celery | +15 |

---

## ğŸ”§ ConfiguraciÃ³n de Docker

### Servicios de Celery en docker-compose.yml

```yaml
# Worker para tareas de scanning
celery_worker_scanning:
  build:
    context: ./backend
    target: production
  command: celery -A app.workers.celery_app:celery_app worker 
           -Q scanning -c 2 --loglevel=info
  depends_on:
    - redis
    - postgres
  environment:
    - CELERY_BROKER_URL=redis://redis:6379/1

# Worker para tareas de enrichment (CVE)
celery_worker_enrichment:
  command: celery -A app.workers.celery_app:celery_app worker 
           -Q enrichment -c 1 --loglevel=info

# Celery Beat para tareas programadas
celery_beat:
  command: celery -A app.workers.celery_app:celery_app beat 
           --loglevel=info
```

### Nmap en Dockerfile

```dockerfile
# Instalar nmap
RUN apt-get update && apt-get install -y \
    nmap \
    && rm -rf /var/lib/apt/lists/*
```

---

## ğŸ“ˆ MÃ©tricas del DÃ­a 6

| MÃ©trica | Valor |
|---------|-------|
| Tests nuevos | 25 |
| Tests totales | 259 |
| LÃ­neas de cÃ³digo | +875 |
| Archivos modificados | 5 |
| Cobertura workers | 100% |

---

## ğŸ¯ PrÃ³ximos Pasos (DÃ­a 7)

### Testing y Refinamiento

1. **Performance Testing**
   - Tests de carga con locust
   - Benchmark de scans concurrentes
   - MediciÃ³n de tiempos de respuesta

2. **Security Testing**
   - ValidaciÃ³n de inputs en targets
   - Rate limiting en creaciÃ³n de scans
   - SanitizaciÃ³n de outputs de Nmap

3. **Refactoring**
   - Crear `scan_service.py` con lÃ³gica de negocio
   - Mejorar manejo de errores en workers
   - Logging estructurado con correlation IDs

4. **DocumentaciÃ³n**
   - OpenAPI schemas completos
   - GuÃ­a de troubleshooting de scans
   - Runbook de operaciones

---

## âœ… Criterios de AceptaciÃ³n Cumplidos

- [x] POST /scans despacha tarea a Celery
- [x] Worker actualiza scan.status durante ejecuciÃ³n
- [x] Worker actualiza scan.progress en tiempo real
- [x] PATCH /cancel termina tarea de Celery
- [x] GET /progress retorna datos reales
- [x] 25+ tests de workers pasando
- [x] Tests de API usan mocks de Celery
- [x] DocumentaciÃ³n actualizada
